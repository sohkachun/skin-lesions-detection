{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231b4598-2804-4c4d-b174-bca393d4001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import multiprocessing as mp\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0d5f2-3054-486a-a1d4-762302e7806c",
   "metadata": {},
   "source": [
    "## Extract data from zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbd5ce6-b8a0-4517-a1e8-7261cce4587a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/train-metadata.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m extract_to_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Extract the ZIP file if needed\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mextract_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_to_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Optionally, remove the ZIP file after extraction\u001b[39;00m\n\u001b[1;32m     41\u001b[0m remove_file(zip_file_path)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mextract_zip\u001b[0;34m(zip_file_path, extract_to_directory)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mExtracts a ZIP file to a specified directory if the files do not already exist.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    extract_to_directory (str): Directory where the ZIP file will be extracted.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Check if extraction directory already contains files from the ZIP\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m extracted_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(extract_to_directory, name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnamelist()]\n\u001b[1;32m     14\u001b[0m files_already_exist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m extracted_files)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files_already_exist:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/zipfile.py:1249\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/train-metadata.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def extract_zip(zip_file_path: str, extract_to_directory: str):\n",
    "    \"\"\"\n",
    "    Extracts a ZIP file to a specified directory if the files do not already exist.\n",
    "\n",
    "    Parameters:\n",
    "        zip_file_path (str): Path to the ZIP file.\n",
    "        extract_to_directory (str): Directory where the ZIP file will be extracted.\n",
    "    \"\"\"\n",
    "    # Check if extraction directory already contains files from the ZIP\n",
    "    extracted_files = [os.path.join(extract_to_directory, name) for name in zipfile.ZipFile(zip_file_path, 'r').namelist()]\n",
    "    files_already_exist = all(os.path.exists(file) for file in extracted_files)\n",
    "\n",
    "    if not files_already_exist:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to_directory)\n",
    "        print(f\"Extracted {zip_file_path} to {extract_to_directory}\")\n",
    "    else:\n",
    "        print(f\"Files already extracted to {extract_to_directory}. Skipping extraction.\")\n",
    "\n",
    "def remove_file(file_path: str):\n",
    "    \"\"\"\n",
    "    Removes a file from the filesystem.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the file to be removed.\n",
    "    \"\"\"\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed {file_path}\")\n",
    "\n",
    "# Paths\n",
    "zip_file_path = \"../data/raw/train-metadata.zip\"\n",
    "extract_to_directory = \"../data/raw/\"\n",
    "\n",
    "# Extract the ZIP file if needed\n",
    "extract_zip(zip_file_path, extract_to_directory)\n",
    "\n",
    "# Optionally, remove the ZIP file after extraction\n",
    "remove_file(zip_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec19c3-d21c-425b-812a-08c5720bc049",
   "metadata": {},
   "source": [
    "## Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b51d1-4f62-4ed9-9bb9-f97720099e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(\"../data/raw/train-metadata.csv\")\n",
    "df_metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fdbdd-6d1f-433f-a1d6-1a7d1c5ab748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(df: pd.DataFrame, include_all: bool = False):\n",
    "    \"\"\"\n",
    "    Print statistics and null value counts for a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "        include_all (bool): If True, include all columns in the descriptive statistics; otherwise, include only numeric columns.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"The DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    # Print descriptive statistics\n",
    "    print(\"Descriptive Statistics:\")\n",
    "    if include_all:\n",
    "        print(df.describe(include='all'))\n",
    "    else:\n",
    "        print(df.describe(include=[np.number]))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "    # Print the number of null values per column\n",
    "    print(\"Null Value Counts:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "    # Additional information: Percentage of null values per column\n",
    "    print(\"Percentage of Null Values:\")\n",
    "    print(df.isnull().mean() * 100)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "    # Number of rows and columns\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f5352-2cae-4e17-8f8f-440af3dc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats(df_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f6776-b60c-4d88-b0d8-3818d13add1c",
   "metadata": {},
   "source": [
    " ## Load Image Byte String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87fdca-17cd-4ab4-87ab-22616c7b522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def load_image_from_hdf5(isic_id: str,\n",
    "                         file_path: str = \"../data/raw/train-image.hdf5\",\n",
    "                         n_channels: int = 3):\n",
    "    # Handle the case where the isic_id is passed incorrectly\n",
    "    if not isic_id.lower().startswith(\"isic\"):\n",
    "        isic_id = f\"ISIC_{int(str(isic_id).split('_', 1)[-1]):>07}\"\n",
    "        \n",
    "    # Open the HDF5 file in read mode\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        \n",
    "        # Retrieve the image data from the HDF5 dataset using the provided ISIC ID\n",
    "        try:\n",
    "            image_data = hf[isic_id][()]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"ISIC ID {isic_id} not found in HDF5 file.\")\n",
    "\n",
    "        # Convert the binary data to a numpy array\n",
    "        image_array = np.frombuffer(image_data, np.uint8)\n",
    "\n",
    "        # Decode the image from the numpy array\n",
    "        if n_channels == 3:\n",
    "            # Load the image as a color image (BGR) and convert to RGB\n",
    "            image = cv2.cvtColor(cv2.imdecode(image_array, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # Load the image as a grayscale image\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # If the image failed to load for some reason (problems decoding) ...\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not decode image for ISIC ID: {isic_id}\")\n",
    "        \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ee644-d5f0-480c-adc8-82083b153fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"ISIC_0015670\", fontweight=\"bold\")\n",
    "plt.imshow(load_image_from_hdf5(\"ISIC_0015670\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
