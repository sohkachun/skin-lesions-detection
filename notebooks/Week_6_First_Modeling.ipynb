{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fc82ad-b4a8-44c1-a9aa-3128957931b1",
   "metadata": {
    "id": "f7fc82ad-b4a8-44c1-a9aa-3128957931b1"
   },
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning and PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# File Handling\n",
    "import h5py\n",
    "\n",
    "# Metrics and Evaluation\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Progress Visualization\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be7e85-2106-4380-b55a-e3ab5e124265",
   "metadata": {
    "id": "84be7e85-2106-4380-b55a-e3ab5e124265"
   },
   "source": [
    "## Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7SW_pt8j6U-j",
   "metadata": {
    "id": "7SW_pt8j6U-j"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, csv_file, transform=None):\n",
    "        # Open the HDF5 file with error handling\n",
    "        try:\n",
    "            self.hdf5_file = h5py.File(hdf5_file, 'r')  # Read-only mode\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Could not open HDF5 file: {hdf5_file}. Error: {e}\")\n",
    "\n",
    "        # Read the CSV file containing image labels and additional features\n",
    "        try:\n",
    "            self.labels_df = pd.read_csv(csv_file)\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Could not read CSV file: {csv_file}. Error: {e}\")\n",
    "\n",
    "        # Ensure that all image IDs from the CSV are present in the HDF5 file\n",
    "        self.image_ids = self.labels_df['isic_id'].values\n",
    "        for image_id in self.image_ids:\n",
    "            if str(image_id) not in self.hdf5_file.keys():\n",
    "                raise ValueError(f\"Image id {image_id} not found in HDF5 file.\")\n",
    "\n",
    "        # Store any transformations to be applied to the images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image ID from the CSV file based on index\n",
    "        image_id = str(self.labels_df.iloc[idx]['isic_id'])\n",
    "\n",
    "        # Load the image data from the HDF5 file\n",
    "        image_bytes = self.hdf5_file[image_id][()]\n",
    "\n",
    "        # Convert the image bytes to a PIL Image\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # Apply any specified transformations to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Retrieve the label\n",
    "        label = torch.tensor(self.labels_df.iloc[idx]['target'], dtype=torch.long)  # Adjust dtype if needed\n",
    "\n",
    "        # Retrieve other features, excluding 'isic_id' and 'target'\n",
    "        other_variables = self.labels_df.iloc[idx].drop(['isic_id', 'target']).values.astype(float)\n",
    "\n",
    "        # Convert other variables (metadata) to a tensor\n",
    "        metadata_tensor = torch.tensor(other_variables, dtype=torch.float32)\n",
    "\n",
    "        # Return the image, metadata, and label\n",
    "        return image, metadata_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefec3fb-19ff-423c-9658-c02dbc82f656",
   "metadata": {
    "editable": true,
    "id": "fefec3fb-19ff-423c-9658-c02dbc82f656",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define any necessary transformations for the image dataset\n",
    "\n",
    "\n",
    "# Transformations for training set (with data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 225x225\n",
    "    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Random crop to 225x225 with scale\n",
    "    transforms.RandomRotation(10),  # Randomly rotate images by 10 degrees\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Transformations for validation/test set (no data augmentation)\n",
    "normal_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Ensure the image is resized to 225x225\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37d748-9b19-40ee-9e42-2c681203548a",
   "metadata": {
    "id": "ac37d748-9b19-40ee-9e42-2c681203548a"
   },
   "source": [
    "## Train DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ninBag9U7qXn",
   "metadata": {
    "id": "ninBag9U7qXn"
   },
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "train_dataset = MultiInputDataset(hdf5_file='../data/raw/train_images.hdf5', csv_file='../data/processed/processed-train-metadata1.csv', transform=normal_transform)\n",
    "val_dataset = MultiInputDataset(hdf5_file='../data/raw/validation_image.hdf5', csv_file='../data/processed/processed-validation-metadata1.csv', transform=normal_transform)\n",
    "# Create a DataLoader\n",
    "train_dataloader = DataLoader(train_dataset,  batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,  batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FcSXckhi0H8i",
   "metadata": {
    "id": "FcSXckhi0H8i"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da66b8-21d6-46ae-a01f-c678a616244a",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa84b6d1-272a-4a02-b252-b35e3bee4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageFeatureCNN2(nn.Module):\n",
    "    def __init__(self, feature_input_size, input_image_size=(128, 128)):\n",
    "        super(CustomImageFeatureCNN2, self).__init__()\n",
    "\n",
    "        # Image CNN with Batch Normalization\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # Batch normalization after conv1\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # Batch normalization after conv2\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)  # Batch normalization after conv3\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 Max pooling\n",
    "\n",
    "        # Dynamically calculate the flattened size of the feature map\n",
    "        self.flattened_size = self._get_flattened_size(input_image_size)\n",
    "\n",
    "        # Fully connected layer after the CNN layers\n",
    "        self.fc_image = nn.Linear(self.flattened_size, 512)\n",
    "\n",
    "        # Fully connected layer for metadata (feature data)\n",
    "        self.fc_metadata = nn.Linear(feature_input_size, 128)\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)  # 50% dropout\n",
    "\n",
    "        # Final fully connected layer for binary classification (combined image + feature input)\n",
    "        self.fc_combined = nn.Linear(512 + 128, 1)  # Change 2 to 1 for binary classification\n",
    "\n",
    "    def _get_flattened_size(self, input_image_size):\n",
    "        # Forward pass a dummy image to get the size of the flattened features\n",
    "        dummy_image = torch.zeros(1, 3, *input_image_size)  # Batch size of 1, 3 channels (RGB), and input size\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(dummy_image))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x.view(-1).shape[0]  # Flatten and return the size\n",
    "\n",
    "    def forward(self, image, metadata):\n",
    "        # Forward pass for the image through the CNN\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(image))))  # Conv layer 1 with ReLU, BatchNorm, MaxPool\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Conv layer 2 with ReLU, BatchNorm, MaxPool\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # Conv layer 3 with ReLU, BatchNorm, MaxPool\n",
    "\n",
    "        # Flatten the feature map to feed into fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten feature maps into a 1D vector\n",
    "        image_features = F.relu(self.fc_image(x))\n",
    "\n",
    "        # Process metadata (feature data)\n",
    "        metadata_features = F.relu(self.fc_metadata(metadata))\n",
    "\n",
    "        # Ensure the batch sizes are consistent\n",
    "        assert image_features.shape[0] == metadata_features.shape[0], \\\n",
    "            f\"Batch sizes do not match! Image batch size: {image_features.shape[0]}, Metadata batch size: {metadata_features.shape[0]}\"\n",
    "\n",
    "        # Concatenate image features and metadata features\n",
    "        combined_features = torch.cat((image_features, metadata_features), dim=1)\n",
    "\n",
    "        # Dropout and final classification layer\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        output = self.fc_combined(combined_features)\n",
    "\n",
    "        # If you're using BCELoss, uncomment the next line to apply sigmoid\n",
    "        output = torch.sigmoid(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d529c-ab86-4f02-8395-011e74b64187",
   "metadata": {
    "id": "ad7d529c-ab86-4f02-8395-011e74b64187"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Au_KwtXzxvS9",
   "metadata": {
    "id": "Au_KwtXzxvS9"
   },
   "outputs": [],
   "source": [
    "# Function to compute partial AUC-above-TPR\n",
    "def score(solution: np.array, submission: np.array, min_tpr: float = 0.80) -> float:\n",
    "    \"\"\"\n",
    "    Compute the partial AUC by focusing on a specific range of true positive rates (TPR).\n",
    "    \n",
    "    Args:\n",
    "        solution (np.array): Ground truth binary labels.\n",
    "        submission (np.array): Model predictions.\n",
    "        min_tpr (float): Minimum true positive rate to calculate partial AUC.\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated partial AUC.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the min_tpr is not within a valid range.\n",
    "    \"\"\"\n",
    "    # Rescale the target to handle sklearn limitations and flip the predictions\n",
    "    v_gt = abs(solution - 1)\n",
    "    v_pred = -1.0 * submission\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "\n",
    "    # Compute ROC curve using sklearn\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(f\"Expected min_tpr in range [0, 1), got: {min_tpr}\")\n",
    "    \n",
    "    # Interpolate for partial AUC\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return partial_auc\n",
    "\n",
    "# Training and validation loop function\n",
    "def train_and_validate(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    val_dataloader: torch.utils.data.DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    early_stopping_patience: int = 5,\n",
    "    min_tpr: float = 0.80\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Train and validate a PyTorch model with early stopping, AUROC, partial AUC, and error handling.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to be trained and validated.\n",
    "        train_dataloader (torch.utils.data.DataLoader): Dataloader for training data.\n",
    "        val_dataloader (torch.utils.data.DataLoader): Dataloader for validation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer to update the model.\n",
    "        epochs (int): Number of training epochs.\n",
    "        device (torch.device): The device (CPU or GPU) to use.\n",
    "        early_stopping_patience (int): Early stopping patience.\n",
    "        min_tpr (float): The minimum true positive rate for calculating partial AUC.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: The trained model.\n",
    "    \"\"\"\n",
    "    # Initialize tracking variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Start the training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        all_train_labels = []\n",
    "        all_train_probs = []\n",
    "\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}')\n",
    "\n",
    "        try:\n",
    "            # Loop through the training batches\n",
    "            for i, (image, metadata, labels) in enumerate(progress_bar):\n",
    "                image, metadata, labels = image.to(device), metadata.to(device), labels.float().to(device)\n",
    "                labels = labels.unsqueeze(1)  # Adjust labels to have the right shape for binary classification\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                probs = model(image, metadata)\n",
    "\n",
    "                if probs.shape != labels.shape:\n",
    "                    raise ValueError(f\"Shape mismatch: Predictions shape {probs.shape} does not match labels shape {labels.shape}\")\n",
    "\n",
    "                # Calculate loss and backpropagate\n",
    "                loss = criterion(probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update running loss\n",
    "                running_train_loss += loss.item()\n",
    "\n",
    "                # Store labels and predictions for accuracy calculations\n",
    "                all_train_labels.extend(labels.cpu().detach().numpy())\n",
    "                all_train_probs.extend(probs.cpu().detach().numpy())\n",
    "\n",
    "                # Calculate binary predictions for training accuracy\n",
    "                predicted_train = (probs >= 0.5).float()\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix(train_loss=running_train_loss / (i + 1))\n",
    "\n",
    "            # Calculate training accuracy and loss\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            train_losses.append(running_train_loss / len(train_dataloader))\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"Error during training loop: {ve}\")\n",
    "            break\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "        progress_bar = tqdm(val_dataloader, desc=f'Validating Epoch {epoch + 1}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Loop through the validation batches\n",
    "                for i, (images, metadata, labels) in enumerate(progress_bar):\n",
    "                    images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "\n",
    "                    probs = model(images, metadata)\n",
    "\n",
    "                    loss = criterion(probs, labels)\n",
    "                    running_val_loss += loss.item()\n",
    "\n",
    "                    all_labels.extend(labels.cpu().detach().numpy())\n",
    "                    all_probs.extend(probs.cpu().detach().numpy())\n",
    "\n",
    "                    # Calculate binary predictions for validation accuracy\n",
    "                    predicted = (probs >= 0.5).float()\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    progress_bar.set_postfix(val_loss=running_val_loss / (i + 1))\n",
    "\n",
    "                val_accuracy = 100 * correct / total\n",
    "                val_loss = running_val_loss / len(val_dataloader)\n",
    "                val_accuracies.append(val_accuracy)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                # Calculate AUROC\n",
    "                try:\n",
    "                    valid_auroc = roc_auc_score(all_labels, all_probs)\n",
    "                except ValueError as ve:\n",
    "                    print(f\"AUROC Calculation Error: {ve}\")\n",
    "                    valid_auroc = 0.0\n",
    "\n",
    "                # Calculate partial AUC-above-TPR\n",
    "                try:\n",
    "                    partial_auroc = score(np.array(all_labels), np.array(all_probs), min_tpr=min_tpr)\n",
    "                except ValueError as ve:\n",
    "                    print(f\"Partial AUC Calculation Error: {ve}\")\n",
    "                    partial_auroc = 0.0\n",
    "\n",
    "                print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "                      f'Val Accuracy: {val_accuracy:.2f}%, Val AUROC: {valid_auroc:.4f}, Partial AUROC: {partial_auroc:.4f}')\n",
    "\n",
    "                # Early stopping based on validation loss\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_epoch = epoch + 1\n",
    "                    early_stopping_counter = 0\n",
    "                    torch.save(model.state_dict(), 'best_model.pth')\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during validation loop: {e}\")\n",
    "                break\n",
    "\n",
    "    print(f\"Best Epoch: {best_epoch}, Best Validation Loss: {best_val_loss:.4f}\")\n",
    "    print('Training Complete')\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Generate classification report\n",
    "    try:\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(all_labels, (np.array(all_probs) >= 0.5).astype(int), target_names=['Class 0', 'Class 1']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating classification report: {e}\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40eb0e1-d23b-453e-b518-93e5e28b9279",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "QB7_Ic9MT633",
   "metadata": {
    "id": "QB7_Ic9MT633"
   },
   "outputs": [],
   "source": [
    "model1 = CustomImageFeatureCNN2(feature_input_size=9)  # Assuming 9 features for metadata\n",
    "model1.to(device)\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "# Define the loss function with the class weights\n",
    "criterion = nn.BCELoss()  # Binary classification loss\n",
    "# Set the number of epochs\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VP0bFWDkvOye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VP0bFWDkvOye",
    "outputId": "716c1538-333d-419a-9846-a653404f5333",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 33/33 [01:24<00:00,  2.57s/it, train_loss=31.3]\n",
      "Validating Epoch 1: 100%|██████████| 24/24 [00:26<00:00,  1.12s/it, val_loss=3.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 31.2748, Val Loss: 3.8411, Val Accuracy: 96.04%, Val AUROC: 0.5000, Partial AUROC: 0.0200\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 33/33 [01:22<00:00,  2.50s/it, train_loss=32.9]\n",
      "Validating Epoch 2: 100%|██████████| 24/24 [00:25<00:00,  1.07s/it, val_loss=3.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 32.9478, Val Loss: 3.8411, Val Accuracy: 96.04%, Val AUROC: 0.5000, Partial AUROC: 0.0200\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 33/33 [01:21<00:00,  2.48s/it, train_loss=33]  \n",
      "Validating Epoch 3: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, val_loss=3.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 33.0222, Val Loss: 3.8411, Val Accuracy: 96.04%, Val AUROC: 0.5000, Partial AUROC: 0.0200\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 33/33 [01:21<00:00,  2.46s/it, train_loss=32.8]\n",
      "Validating Epoch 4: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, val_loss=3.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 32.7990, Val Loss: 3.8411, Val Accuracy: 96.04%, Val AUROC: 0.5000, Partial AUROC: 0.0200\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 33/33 [01:19<00:00,  2.41s/it, train_loss=32.9]\n",
      "Validating Epoch 5: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, val_loss=4.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 32.9230, Val Loss: 4.3403, Val Accuracy: 96.04%, Val AUROC: 0.5000, Partial AUROC: 0.0200\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:   6%|▌         | 2/33 [00:04<01:16,  2.47s/it, train_loss=33.6]"
     ]
    }
   ],
   "source": [
    "train_and_validate(model1,train_dataloader, val_dataloader, criterion, optimizer, epochs, device )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OFMQCQpldSHJ",
   "metadata": {
    "id": "OFMQCQpldSHJ"
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RprU4gYXoC_4",
   "metadata": {
    "id": "RprU4gYXoC_4"
   },
   "outputs": [],
   "source": [
    "model2 = CustomImageFeatureCNN2(feature_input_size=9)  # Assuming 9 features for metadata\n",
    "model2.to(device)\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.001)\n",
    "# Define the loss function with the class weights\n",
    "criterion = nn.BCELoss()  # Binary classification loss\n",
    "# Set the number of epochs\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czjkFLKEo9DA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czjkFLKEo9DA",
    "outputId": "4b4608d5-62f3-4d0b-b3ad-23561bd6f020"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_and_validate(model2,train_dataloader, val_dataloader, criterion, optimizer, epochs, device )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644c143-cf66-47fd-a14f-48562bf4e6a0",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IRGVtC5lpP6M",
   "metadata": {
    "id": "IRGVtC5lpP6M"
   },
   "outputs": [],
   "source": [
    "model3 = CustomImageFeatureCNN2(feature_input_size=9)  # Assuming 9 features for metadata\n",
    "model3.to(device)\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "# Define the loss function with the class weights\n",
    "criterion = nn.BCELoss()  # Binary classification loss\n",
    "# Set the number of epochs\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_HktePpbyPCL",
   "metadata": {
    "id": "_HktePpbyPCL"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "etUGo_AEpviL",
   "metadata": {
    "id": "etUGo_AEpviL"
   },
   "outputs": [],
   "source": [
    "train_and_validate(model3,train_dataloader, val_dataloader, criterion, optimizer, epochs, device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XcaJflPD3GOM",
   "metadata": {
    "id": "XcaJflPD3GOM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df69515-360d-4f58-b8df-bd75d262d662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
